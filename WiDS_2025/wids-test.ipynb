{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":90566,"databundleVersionId":11498594,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport torch \nimport os\nimport numpy as np\nRANDOM_STATE_1 = 1998\nRANDOM_STATE_2 = 42\ndef set_seed(seed: int = 42) -> None:\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    print(f\"Random seed set as {seed}\")\n\nset_seed(RANDOM_STATE_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:23:36.127287Z","iopub.execute_input":"2025-03-29T12:23:36.127571Z","iopub.status.idle":"2025-03-29T12:23:39.510305Z","shell.execute_reply.started":"2025-03-29T12:23:36.127538Z","shell.execute_reply":"2025-03-29T12:23:39.509395Z"}},"outputs":[{"name":"stdout","text":"Random seed set as 1998\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Part 1: preprocessing data","metadata":{}},{"cell_type":"markdown","source":"## Read data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntrain_data_dir = \"/kaggle/input/widsdatathon2025/TRAIN_NEW\"\ntrain_solutions = pd.read_excel(train_data_dir + \"/TRAINING_SOLUTIONS.xlsx\")\ntrain_categorical = pd.read_excel(train_data_dir + \"/TRAIN_CATEGORICAL_METADATA_new.xlsx\")\ntrain_functional = pd.read_csv(train_data_dir + \\\n                               \"/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\ntrain_metadata = pd.read_excel(train_data_dir + \"/TRAIN_QUANTITATIVE_METADATA_new.xlsx\")\n\ntest_data_dir = \"/kaggle/input/widsdatathon2025/TEST\"\ntest_functional = pd.read_csv(test_data_dir + \\\n                               \"/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:23:39.511025Z","iopub.execute_input":"2025-03-29T12:23:39.511317Z","iopub.status.idle":"2025-03-29T12:23:59.740083Z","shell.execute_reply.started":"2025-03-29T12:23:39.511298Z","shell.execute_reply":"2025-03-29T12:23:59.739346Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"print(\"train_solutions:\", train_solutions.shape, \n      \"\\n train_solutions key\", train_solutions.keys())\nprint(\"train_functional:\", train_functional.shape,\n     \"\\n train_functional key\", train_functional.keys())\nprint(\"train_metadata:\", train_metadata.shape,\n     \"\\n train_metadata\", train_metadata.keys())\nprint(\"train_categorical:\", train_categorical.shape,\n     \"\\n train_categorical\", train_categorical.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:23:59.740855Z","iopub.execute_input":"2025-03-29T12:23:59.741108Z","iopub.status.idle":"2025-03-29T12:23:59.749836Z","shell.execute_reply.started":"2025-03-29T12:23:59.741087Z","shell.execute_reply":"2025-03-29T12:23:59.749131Z"}},"outputs":[{"name":"stdout","text":"train_solutions: (1213, 3) \n train_solutions key Index(['participant_id', 'ADHD_Outcome', 'Sex_F'], dtype='object')\ntrain_functional: (1213, 19901) \n train_functional key Index(['participant_id', '0throw_1thcolumn', '0throw_2thcolumn',\n       '0throw_3thcolumn', '0throw_4thcolumn', '0throw_5thcolumn',\n       '0throw_6thcolumn', '0throw_7thcolumn', '0throw_8thcolumn',\n       '0throw_9thcolumn',\n       ...\n       '195throw_196thcolumn', '195throw_197thcolumn', '195throw_198thcolumn',\n       '195throw_199thcolumn', '196throw_197thcolumn', '196throw_198thcolumn',\n       '196throw_199thcolumn', '197throw_198thcolumn', '197throw_199thcolumn',\n       '198throw_199thcolumn'],\n      dtype='object', length=19901)\ntrain_metadata: (1213, 19) \n train_metadata Index(['participant_id', 'EHQ_EHQ_Total', 'ColorVision_CV_Score',\n       'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV',\n       'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP',\n       'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total',\n       'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing',\n       'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity',\n       'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial',\n       'MRI_Track_Age_at_Scan'],\n      dtype='object')\ntrain_categorical: (1213, 10) \n train_categorical Index(['participant_id', 'Basic_Demos_Enroll_Year', 'Basic_Demos_Study_Site',\n       'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race',\n       'MRI_Track_Scan_Location', 'Barratt_Barratt_P1_Edu',\n       'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu',\n       'Barratt_Barratt_P2_Occ'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Construct cor variance matrix","metadata":{}},{"cell_type":"code","source":"!pip install -q torch_geometric\n!pip install -q geomstats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:23:59.751619Z","iopub.execute_input":"2025-03-29T12:23:59.751891Z","iopub.status.idle":"2025-03-29T12:24:09.733655Z","shell.execute_reply.started":"2025-03-29T12:23:59.751857Z","shell.execute_reply":"2025-03-29T12:24:09.732821Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# n_regions = 200\n# n_samples = train_functional.shape[0]\n# adj_mat = np.zeros((200,200))\n\n# start_idx = 0\n\n# def construct_corvar(df_row, n_regions):\n#     adj = np.ones((n_regions, n_regions))\n#     num_adj = n_regions - 1\n#     start_idx = 0\n#     for j in range(n_regions):\n#         for i in range(n_regions - num_adj, num_adj):\n#             adj[i][j] = df_row.iloc[start_idx + i]\n#         num_adj -= 1\n#         start_idx += num_adj\n#     return adj \n\n# train_data = []\n\n# for i in n_samples:\n#     adj = construct_corvar(train_functional.iloc[i])\n#     train_data.append(adj)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:24:09.735647Z","iopub.execute_input":"2025-03-29T12:24:09.736030Z","iopub.status.idle":"2025-03-29T12:24:09.739699Z","shell.execute_reply.started":"2025-03-29T12:24:09.735994Z","shell.execute_reply":"2025-03-29T12:24:09.738856Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Construct symmetric matrices","metadata":{}},{"cell_type":"code","source":"import geomstats.datasets.utils as data_utils\nimport geomstats.backend as gs\nfrom geomstats.geometry.skew_symmetric_matrices import SkewSymmetricMatrices\n\ndef load_connectomes(df_conn, df_soln_adhd=train_solutions, as_vectors=False, test=False):\n        patient_id = gs.array(df_conn[\"participant_id\"])\n        data = gs.array(df_conn.drop('participant_id', axis=1))\n        targets = gs.array(df_soln_adhd[['ADHD_Outcome', 'Sex_F']])\n        if test==True:\n            return mat, patient_id\n        if as_vectors:\n            target_ADHD = targets[:,0]\n            target_sex = targets[:,1]\n            return data, patient_id, target_ADHD, target_sex\n\n        mat = SkewSymmetricMatrices(200).matrix_representation(data)\n        mat = gs.eye(200) - gs.transpose(gs.tril(mat), (0,2,1))\n        mat = 1.0/2.0 * (mat + gs.transpose(mat, (0,2,1)))\n        return mat, patient_id, targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:24:09.740419Z","iopub.execute_input":"2025-03-29T12:24:09.740742Z","iopub.status.idle":"2025-03-29T12:24:10.145801Z","shell.execute_reply.started":"2025-03-29T12:24:09.740709Z","shell.execute_reply":"2025-03-29T12:24:10.145137Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"data, patient_id, labels = load_connectomes(train_functional, train_solutions)\n\nfrom geomstats.geometry.spd_matrices import SPDMatrices\nmanifold = SPDMatrices(200, equip=False)\nprint(gs.all(manifold.belongs(data)))\ncount_false = np.sum(~(manifold.belongs(data)))\nprint(\"Count of False:\", count_false)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:24:10.146556Z","iopub.execute_input":"2025-03-29T12:24:10.147185Z","iopub.status.idle":"2025-03-29T12:36:46.831893Z","shell.execute_reply.started":"2025-03-29T12:24:10.147160Z","shell.execute_reply":"2025-03-29T12:36:46.831102Z"}},"outputs":[{"name":"stdout","text":"True\nCount of False: 0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Ensuring SPD Property","metadata":{}},{"cell_type":"code","source":"def add_diagonal_correction(matrix):\n    eigenvalues = np.linalg.eigvals(matrix)\n    min_eigenvalue = np.min(eigenvalues)\n\n    if min_eigenvalue < 0:\n        correction = -min_eigenvalue + 1e-6\n        correction_matrix = correction * np.eye(matrix.shape[0])\n        return matrix + correction_matrix\n    else:\n        return matrix\n\ndata_corrected = np.array([add_diagonal_correction(slice) for slice in data])\nprint(\"Original Matrix shape:\", data.shape)\nprint(\"Corrected Matrix shape:\", data_corrected.shape)\nprint(gs.all(manifold.belongs(data_corrected)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:36:46.832649Z","iopub.execute_input":"2025-03-29T12:36:46.832905Z","iopub.status.idle":"2025-03-29T12:36:54.414281Z","shell.execute_reply.started":"2025-03-29T12:36:46.832882Z","shell.execute_reply":"2025-03-29T12:36:54.413369Z"}},"outputs":[{"name":"stdout","text":"Original Matrix shape: (1213, 200, 200)\nCorrected Matrix shape: (1213, 200, 200)\nTrue\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Part 2: GCN","metadata":{}},{"cell_type":"markdown","source":"## Data preparation","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\n\nconnectivity_matrices = torch.tensor(data_corrected).float()\nlabels = torch.tensor(labels).float()\n\ndata_list = []\nfor i in range(len(connectivity_matrices)):\n    matrix = connectivity_matrices[i]\n    edge_index = (matrix > 0).nonzero(as_tuple=False).t()\n    edge_attr = matrix[edge_index[0], edge_index[1]]\n    x = torch.eye(200)\n\n    graph_data = Data(x=x, edge_index=edge_index,\n                     edge_attr=edge_attr, y=labels[i].unsqueeze(0))\n\n    data_list.append(graph_data)\n\ntrain_data_list = data_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:36:54.415249Z","iopub.execute_input":"2025-03-29T12:36:54.415529Z","iopub.status.idle":"2025-03-29T12:36:59.764758Z","shell.execute_reply.started":"2025-03-29T12:36:54.415507Z","shell.execute_reply":"2025-03-29T12:36:59.764039Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Define models","metadata":{}},{"cell_type":"code","source":"class GCN(torch.nn.Module):\n    def __init__(self, num_layers):\n        super(GCN, self).__init__()\n        self.conv1 = GCNConv(in_channels=200,out_channels=128)\n        self.in_channels = 128\n        self.num_layers = num_layers\n        self.layers = nn.ModuleList()\n        hidden_dim = self.in_channels\n        for i in range(num_layers):\n            if (i == num_layers-1):\n                self.layers.append(GCNConv(in_channels=hidden_dim, out_channels=2))\n            else:\n                out_dim = max(hidden_dim // 2, 1)\n                self.layers.append(GCNConv(in_channels=hidden_dim, out_channels=out_dim))\n                hidden_dim = out_dim   \n            \n    def forward(self, data):\n        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n        x = self.conv1(x, edge_index, edge_attr)\n        x = F.relu(x)\n        for layer in self.layers:\n            x = layer(x, edge_index, edge_attr)\n            x = F.relu(x)\n\n        x = global_mean_pool(x, batch)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:36:59.765574Z","iopub.execute_input":"2025-03-29T12:36:59.766034Z","iopub.status.idle":"2025-03-29T12:36:59.772711Z","shell.execute_reply.started":"2025-03-29T12:36:59.766009Z","shell.execute_reply":"2025-03-29T12:36:59.771749Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:36:59.773636Z","iopub.execute_input":"2025-03-29T12:36:59.773959Z","iopub.status.idle":"2025-03-29T12:36:59.801944Z","shell.execute_reply.started":"2025-03-29T12:36:59.773929Z","shell.execute_reply":"2025-03-29T12:36:59.801296Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Hyperparameters and training ","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntuning = False\nn_trials = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:36:59.802600Z","iopub.execute_input":"2025-03-29T12:36:59.802820Z","iopub.status.idle":"2025-03-29T12:36:59.817392Z","shell.execute_reply.started":"2025-03-29T12:36:59.802774Z","shell.execute_reply":"2025-03-29T12:36:59.816641Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"!pip install -q iterative-stratification\n!pip install -q optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:36:59.820443Z","iopub.execute_input":"2025-03-29T12:36:59.820657Z","iopub.status.idle":"2025-03-29T12:37:06.960715Z","shell.execute_reply.started":"2025-03-29T12:36:59.820640Z","shell.execute_reply":"2025-03-29T12:37:06.959576Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef evaluate_model(model, data_loader, device, log=False):\n    model.eval()\n    actual_adhd, pred_adhd = [], []\n    actual_sex, pred_sex = [], []\n\n    with torch.no_grad():\n        for batch_data in data_loader:\n            batch_data = batch_data.to(device)\n            out = model(batch_data)\n            preds = torch.round(torch.sigmoid(out))\n\n            actual_adhd.extend(batch_data.y[:,0].int().cpu().tolist())\n            pred_adhd.extend(preds[:,0].int().cpu().tolist())\n            actual_sex.extend(batch_data.y[:,1].int().cpu().tolist())\n            pred_sex.extend(preds[:,1].int().cpu().tolist())\n\n    f1_adhd = f1_score(actual_adhd, pred_adhd)\n    f1_sex = f1_score(actual_sex, pred_sex)\n    avg_f1 = (f1_adhd + f1_sex) / 2.0\n    if log:\n        print(f\"F1 ADHD: {f1_adhd:.4f}, F1 Sex: {f1_sex:.4f}, Avg F1: {avg_f1:.4f}\")\n    return f1_adhd, f1_sex, avg_f1\n\ndef evaluate_model_debug(model, data_loader, device, log=False):\n    model.eval()\n    all_preds = []\n    with torch.no_grad():\n        for batch_data in data_loader:\n            batch_data = batch_data.to(device)\n            out = model(batch_data)\n            preds = torch.sigmoid(out)\n            all_preds.append(preds.cpu())\n    all_preds = torch.cat(all_preds, dim=0)\n    if log:\n        print(\"Raw predictions (first 10):\", all_preds[:1])\n    return all_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:45:47.703995Z","iopub.execute_input":"2025-03-29T12:45:47.704303Z","iopub.status.idle":"2025-03-29T12:45:47.711928Z","shell.execute_reply.started":"2025-03-29T12:45:47.704280Z","shell.execute_reply":"2025-03-29T12:45:47.710865Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def training(model, optimizer, criterion, train_loader, val_loader, device, num_epochs=200, patience=50):\n    losses = []\n    best_val_score = 0\n    epochs_no_improve = 0\n    softmax = torch.nn.Softmax(dim=1)\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        for data in train_loader:\n            data = data.to(device)\n            optimizer.zero_grad()\n            out = model(data)\n            out = softmax(out)\n            loss_ADHD = criterion(out[:,0], data.y[:,0])\n            loss_sex = criterion(out[:,1], data.y[:,1])\n            loss = loss_ADHD + loss_sex\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        \n        avg_loss = total_loss / len(train_loader)\n        losses.append(avg_loss)\n        \n        if epoch % 10 == 0:\n            print(f\"Epoch {epoch}, Loss: {avg_loss:.4f}\")\n            # print(f\"Evaluating train in epoch {epoch}...\")\n            # f1_adhd_tr, f1_sex_tr, avg_f1_tr = evaluate_model(model, train_loader, device, log=True)\n            print(f\"Evaluating val in epoch {epoch}...\")\n            f1_adhd_val, f1_sex_val, avg_f1_val = evaluate_model(model, val_loader, device, log=True)\n        else: \n            f1_adhd_val, f1_sex_val, avg_f1_val = evaluate_model(model, val_loader, device)\n        \n        if avg_f1_val > best_val_score:\n            best_val_score = avg_f1_val\n            epochs_no_improve = 0\n        else:\n            epochs_no_improve += 1\n\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping triggered at epoch {epoch}\")\n            break\n\n    return model, f1_adhd_val, f1_sex_val, avg_f1_val","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:37:18.483883Z","iopub.execute_input":"2025-03-29T13:37:18.484220Z","iopub.status.idle":"2025-03-29T13:37:18.491508Z","shell.execute_reply.started":"2025-03-29T13:37:18.484193Z","shell.execute_reply":"2025-03-29T13:37:18.490730Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"import optuna\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\ndef objective(trial):\n    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-1)\n    num_layers = trial.suggest_int(\"num_layers\", 1,4)\n    batch_size = trial.suggest_categorical(\"batch_size\", [16,32,64])\n    num_epochs = trial.suggest_int(\"num_epochs\", 50, 200)\n    patience = trial.suggest_int(\"patience\",10,50)\n    labels_np = labels.cpu().numpy()\n    indices = np.arange(len(train_data_list))\n\n    mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    fold_scores = []\n\n    for train_idx, val_idx in mskf.split(indices, labels_np):\n        train_fold = [train_data_list[i] for i in train_idx]\n        val_fold = [train_data_list[i] for i in val_idx]\n\n        train_loader = DataLoader(train_fold, batch_size=batch_size, shuffle=True)\n        val_loader = DataLoader(val_fold, batch_size=batch_size, shuffle=True)\n        model = GCN(num_layers=num_layers).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n        criterion = torch.nn.BCEWithLogitsLoss()\n        model, f1_adhd_val, f1_sex_val, avg_f1_val = training(model, optimizer, criterion, train_loader, val_loader, \\\n                                                              device, num_epochs=num_epochs, patience=patience)\n        fold_scores.append(avg_f1_val)\n    return np.mean(fold_scores)       ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:37:07.097866Z","iopub.execute_input":"2025-03-29T12:37:07.098127Z","iopub.status.idle":"2025-03-29T12:37:07.332571Z","shell.execute_reply.started":"2025-03-29T12:37:07.098074Z","shell.execute_reply":"2025-03-29T12:37:07.331933Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"if tuning:\n    best_params = study.best_trial.params\n    lr = best_params[\"lr\"]\n    num_layers = best_params[\"num_layers\"]\n    batch_size = best_params[\"batch_size\"]\n    num_epochs = best_params[\"num_epochs\"]\n    patience = best_params[\"patience\"]\n\nelse: \n    lr = 0.01\n    num_layers = 4\n    num_epochs = 300\n    batch_size = 32\n    patience = 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:55:19.719404Z","iopub.execute_input":"2025-03-29T13:55:19.719722Z","iopub.status.idle":"2025-03-29T13:55:19.724268Z","shell.execute_reply.started":"2025-03-29T13:55:19.719699Z","shell.execute_reply":"2025-03-29T13:55:19.723375Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"n_splits=5\nmskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\nfold_scores = []\nlabels_np = labels.cpu().numpy()\nindices = np.arange(len(train_data_list))\n\nfor train_idx, val_idx in mskf.split(indices, labels_np):\n    train_fold = [train_data_list[i] for i in train_idx]\n    val_fold = [train_data_list[i] for i in val_idx]\n\n    train_loader = DataLoader(train_fold, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_fold, batch_size=batch_size, shuffle=True)\n    model = GCN(num_layers=num_layers).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    criterion = torch.nn.CrossEntropyLoss()\n    model, f1_adhd_val, f1_sex_val, avg_f1_val = training(model, optimizer, criterion, train_loader, val_loader, \\\n                                                              device, num_epochs=num_epochs, patience=patience)\n    fold_scores.append(avg_f1_val)\n    \nprint(f\"Avg f1-score between {n_splits} folds\", np.mean(fold_scores))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:55:22.132153Z","iopub.execute_input":"2025-03-29T13:55:22.132569Z","iopub.status.idle":"2025-03-29T13:58:11.366998Z","shell.execute_reply.started":"2025-03-29T13:55:22.132529Z","shell.execute_reply":"2025-03-29T13:58:11.365803Z"}},"outputs":[{"name":"stdout","text":"Epoch 0, Loss: 111.2305\nEvaluating val in epoch 0...\nF1 ADHD: 0.8137, F1 Sex: 0.5108, Avg F1: 0.6622\nEpoch 10, Loss: 111.1954\nEvaluating val in epoch 10...\nF1 ADHD: 0.8137, F1 Sex: 0.0000, Avg F1: 0.4069\nEpoch 20, Loss: 111.2988\nEvaluating val in epoch 20...\nF1 ADHD: 0.8137, F1 Sex: 0.0000, Avg F1: 0.4069\nEpoch 30, Loss: 111.0232\nEvaluating val in epoch 30...\nF1 ADHD: 0.8137, F1 Sex: 0.0000, Avg F1: 0.4069\nEpoch 40, Loss: 111.2299\nEvaluating val in epoch 40...\nF1 ADHD: 0.8137, F1 Sex: 0.0000, Avg F1: 0.4069\nEpoch 50, Loss: 111.1610\nEvaluating val in epoch 50...\nF1 ADHD: 0.8137, F1 Sex: 0.0000, Avg F1: 0.4069\nEpoch 60, Loss: 111.1265\nEvaluating val in epoch 60...\nF1 ADHD: 0.8137, F1 Sex: 0.0000, Avg F1: 0.4069\nEpoch 70, Loss: 111.1610\nEvaluating val in epoch 70...\nF1 ADHD: 0.8137, F1 Sex: 0.0000, Avg F1: 0.4069\nEpoch 80, Loss: 111.1265\nEvaluating val in epoch 80...\nF1 ADHD: 0.8137, F1 Sex: 0.0000, Avg F1: 0.4069\nEpoch 90, Loss: 111.1610\nEvaluating val in epoch 90...\nF1 ADHD: 0.8137, F1 Sex: 0.0000, Avg F1: 0.4069\nEpoch 100, Loss: 111.1954\nEvaluating val in epoch 100...\nF1 ADHD: 0.8137, F1 Sex: 0.0000, Avg F1: 0.4069\nEarly stopping triggered at epoch 100\nEpoch 0, Loss: 111.1269\nEvaluating val in epoch 0...\nF1 ADHD: 0.8137, F1 Sex: 0.0000, Avg F1: 0.4069\nEpoch 10, Loss: 111.1954\nEvaluating val in epoch 10...\nF1 ADHD: 0.0000, F1 Sex: 0.0000, Avg F1: 0.0000\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-0de93a20ea57>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     model, f1_adhd_val, f1_sex_val, avg_f1_val = training(model, optimizer, criterion, train_loader, val_loader, \\\n\u001b[0m\u001b[1;32m     17\u001b[0m                                                               device, num_epochs=num_epochs, patience=patience)\n\u001b[1;32m     18\u001b[0m     \u001b[0mfold_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_f1_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-765dac68e591>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, optimizer, criterion, train_loader, val_loader, device, num_epochs, patience)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss_ADHD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-4d488e8975c1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0m\u001b[1;32m    242\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         edge_index, edge_weight = add_remaining_self_loops(\n\u001b[0m\u001b[1;32m    100\u001b[0m             edge_index, edge_weight, fill_value, num_nodes)\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/loop.py\u001b[0m in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mloop_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0medge_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0mis_undirected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":43},{"cell_type":"markdown","source":"## Performance on train","metadata":{}},{"cell_type":"code","source":"# from sklearn.metrics import accuracy_score, \\\n#                             f1_score\n\n# actual_labels_ADHD = []\n# predicted_labels_ADHD = []\n# actual_labels_sex = []\n# predicted_labels_sex = []\n\n# model.eval()\n# with torch.no_grad():\n#     for batch_data in train_loader:\n#         batch_data = batch_data.to(device)\n#         out = model(batch_data)\n#         # Apply sigmoid and round for binary predictions\n#         pred = torch.round(torch.sigmoid(out))\n#         # Assume batch_data.y has shape [batch_size, 2]; extract each target column\n#         actual_labels_ADHD.extend(batch_data.y[:, 0].int().tolist())\n#         predicted_labels_ADHD.extend(pred[:, 0].int().tolist())\n#         actual_labels_sex.extend(batch_data.y[:, 1].int().tolist())\n#         predicted_labels_sex.extend(pred[:, 1].int().tolist())\n\n# accuracy_ADHD = accuracy_score(actual_labels_ADHD, predicted_labels_ADHD)\n# accuracy_sex = accuracy_sex(actual_labels_sex, predicted_labels_sex)\n# accuracy = (accuracy_ADHD + accuracy_sex)/2\n\n# f1_ADHD = f1_score(actual_labels_ADHD, predicted_labels_ADHD)\n# f1_sex = f1_sex(actual_labels_sex, predicted_labels_sex)\n# f1 = (f1_ADHD + f1_sex)/2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:37:09.992872Z","iopub.status.idle":"2025-03-29T12:37:09.993130Z","shell.execute_reply":"2025-03-29T12:37:09.993028Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prepare test set for inference","metadata":{}},{"cell_type":"code","source":"data_test, patient_id_test = load_connectomes(test_functional, test=True)\ndata_corrected_test = np.array([add_diagonal_correction(slice) for slice in data_test])\nconnectivity_matrices_test = torch.tensor(data_corrected_test).float()\n\ndata_list_test = []\nfor i in range(len(connectivity_matrices_test)):\n    matrix = connectivity_matrices_test[i]\n    edge_index = (matrix > 0).nonzero(as_tuple=False).t()\n    edge_attr = matrix[edge_index[0], edge_index[1]]\n    x = torch.eye(200)\n\n    dummy_label = torch.zeros(2)\n\n    graph_data = Data(x=x, edge_index=edge_index,\n                     edge_attr=edge_attr, y=dummy_label)\n\n    data_list_test.append(graph_data)\n\ntest_data = data_list_test\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:37:09.993656Z","iopub.status.idle":"2025-03-29T12:37:09.993949Z","shell.execute_reply":"2025-03-29T12:37:09.993836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\npredicted_labels_ADHD = []\npredicted_labels_sex = []\nwith torch.no_grad():\n    for data in test_loader:\n        data = data.to(device)\n        out = model(data)\n        pred = torch.round(torch.sigmoid(out))\n        predicted_labels_ADHD.extend(pred[:,0].cpu().numpy().tolist())\n        predicted_labels_sex.extend(pred[1].cpu().numpy().tolist())\n\nimport pandas as pd\nresult1 = pd.DataFrame({\n    'participant_id': patient_id_test,\n    'ADHD_Outcome': predicted_labels_ADHD,\n    'Sex_F': predicted_labels_sex\n})\n# result.to_csv(\"kaggle/working/submission.csv\", index=False)\n# result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:37:09.994720Z","iopub.status.idle":"2025-03-29T12:37:09.995004Z","shell.execute_reply":"2025-03-29T12:37:09.994883Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Part 2: Ensemble voting","metadata":{}},{"cell_type":"markdown","source":"## Loading features","metadata":{}},{"cell_type":"code","source":"def get_feats(data_dir, mode=\"TRAIN\"):\n    meta = pd.read_excel(os.path.join(data_dir, f\"{mode}_QUANTITATIVE_METADATA.xlsx\")\n    cate = pd.read_excel(os.path.join(data_dir, f\"{mode}_CATEGORICAL_METADATA.xlsx\"))\n    func = pd.read_csv(os.path.join(data_dir, f\"{mode}_FUNCTIONAL_CONNECTOME_MATRICES.csv\"))\n    feats = feats.merge(cate, on='participant_id', how='left')\n    feats = feats.merge(func, on='participant_id', how='left')\n    if mode == 'TRAIN':\n        solution = pd.read_excel(os.path.join(data_dir, \"TRAINING_SOLUTIONS.xlsx\"))\n        feats = feats.merge(solution, on='participant_id', how='left')\n    return feat\n\ntrain = get_feats(mode='TRAIN')\ntest = get_feats(mode='TEST')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:37:09.995898Z","iopub.status.idle":"2025-03-29T12:37:09.996174Z","shell.execute_reply":"2025-03-29T12:37:09.996067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def check_for_nulls(df):\n    if df.isnull().any().any():\n        print(\"The DataFrame contains null values.\")\n    else:\n        print(\"The DataFrame does not contain null values.\")\n\ncheck_for_nulls(train)\ncheck_for_nulls(test)\nprint(f'Train: {train.shape}, Test: {test.shape}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:37:09.997072Z","iopub.status.idle":"2025-03-29T12:37:09.997411Z","shell.execute_reply":"2025-03-29T12:37:09.997240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.set_index('participant_id',inplace=True)\ntest.set_index('participant_id',inplace=True)\ntargets = train[['ADHD_Outcome','Sex_F']]\nfeatures = test.columns\nlog_features = [f for f in features if (train[f] >= 0).all() and scipy.stats.skew(train[f]) > 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:37:09.998215Z","iopub.status.idle":"2025-03-29T12:37:09.998478Z","shell.execute_reply":"2025-03-29T12:37:09.998370Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Handling missing values","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.feature_selection import RFECV, SequentialFeatureSelector, SelectKBest\n\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestClassifier\n\nmskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nindices = np.arange(len(train))\ntargets_np = np.array(targets)\nfor train_idx, val_idx in mskf.split(indices, targets_np):\n    train_fold = [train[i] for i in train_idx]\n    train_target = [target_np[i] for i in train_idx]\n    val_fold = [train[i] for i in val_idx]\n    val_target = [target_np[i] for i in val_idx]\n\n    model = MultiOutputClassifier(make_pipeline(\n                        \n                              ColumnTransformer([('imputer',SimpleImputer(),features)],\n                                               remainder='passthrough',\n                                               verbose_feature_names_out=False).set_output(transform='pandas'),\n                              ColumnTransformer([('log', \n                                                 FunctionTransformer(np.log1p), log_features)],\n                                                 remainder='passthrough'),\n                              \n                            MinMaxScaler(),    \n                              \n                            RidgeClassifier(alpha=100)))\n    model.fit(train_fold, train_target)\n    val_pred = model.predict(val_fold)\n    fold_scores = f1_score(val_pred, val_fold)\n    fold_scores.append(avg_f1_val)\n\nprint(\"Validation fold scores\", np.mean(fold_scores))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:37:09.999405Z","iopub.status.idle":"2025-03-29T12:37:09.999720Z","shell.execute_reply":"2025-03-29T12:37:09.999604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = MultiOutputClassifier(make_pipeline(ColumnTransformer([('imputer',SimpleImputer(),features)],\n                                               remainder='passthrough',\n                                               verbose_feature_names_out=False).set_output(transform='pandas'),\n                                              ColumnTransformer([('log', \n                                                 FunctionTransformer(np.log1p), log_features)],\n                                                 remainder='passthrough'),\n                                            MinMaxScaler(),  \n                                            PCA(1087),\n                                            RidgeClassifier(alpha=100)))\nmodel.fit(train.drop(targets,axis=1),\n          targets)\ny_pred = model.predict(test)\nsub['ADHD_Outcome'] = y_pred[:,0]\nsub['Sex_F'] = y_pred[:,1]\nsub.to_csv('submission.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:37:10.000344Z","iopub.status.idle":"2025-03-29T12:37:10.000623Z","shell.execute_reply":"2025-03-29T12:37:10.000509Z"}},"outputs":[],"execution_count":null}]}